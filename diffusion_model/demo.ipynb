{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install Pillow\n",
    "%pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ds45a\\OneDrive - MSFT\\project\\Diffusion_model_from_scratch\\sd\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ds45a\\OneDrive - MSFT\\project\\Diffusion_model_from_scratch\\sd\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1454, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ds45a\\OneDrive - MSFT\\project\\Diffusion_model_from_scratch\\sd\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1345, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ds45a\\OneDrive - MSFT\\project\\Diffusion_model_from_scratch\\sd\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ds45a\\OneDrive - MSFT\\project\\Diffusion_model_from_scratch\\sd\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ds45a\\OneDrive - MSFT\\project\\Diffusion_model_from_scratch\\sd\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1179, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ds45a\\OneDrive - MSFT\\project\\Diffusion_model_from_scratch\\sd\\Lib\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"c:\\Users\\ds45a\\OneDrive - MSFT\\project\\Diffusion_model_from_scratch\\sd\\Lib\\site-packages\\stack_data\\utils.py\", line 83, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"c:\\Users\\ds45a\\OneDrive - MSFT\\project\\Diffusion_model_from_scratch\\sd\\Lib\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ds45a\\OneDrive - MSFT\\project\\Diffusion_model_from_scratch\\sd\\Lib\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ds45a\\OneDrive - MSFT\\project\\Diffusion_model_from_scratch\\sd\\Lib\\site-packages\\executing\\executing.py\", line 264, in executing\n",
      "    source = cls.for_frame(frame)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ds45a\\OneDrive - MSFT\\project\\Diffusion_model_from_scratch\\sd\\Lib\\site-packages\\executing\\executing.py\", line 183, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ds45a\\OneDrive - MSFT\\project\\Diffusion_model_from_scratch\\sd\\Lib\\site-packages\\executing\\executing.py\", line 212, in for_filename\n",
      "    return cls._for_filename_and_lines(filename, tuple(lines))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ds45a\\OneDrive - MSFT\\project\\Diffusion_model_from_scratch\\sd\\Lib\\site-packages\\executing\\executing.py\", line 223, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "                                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ds45a\\OneDrive - MSFT\\project\\Diffusion_model_from_scratch\\sd\\Lib\\site-packages\\executing\\executing.py\", line 163, in __init__\n",
      "    self.tree = ast.parse(self.text, filename=filename)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Python312\\Lib\\ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "MemoryError\n"
     ]
    }
   ],
   "source": [
    "import model_loader\n",
    "import pipeline\n",
    "from PIL import Image\n",
    "from transformers import CLIPTokenizer\n",
    "import torch.backends as backend\n",
    "import torch\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "ALLOW_CUDA = False\n",
    "ALLOW_MPS = False \n",
    "\n",
    "if torch.cuda.is_available() and ALLOW_CUDA:\n",
    "    DEVICE = \"cuda\"\n",
    "elif torch.cuda.is_available() and ALLOW_MPS:\n",
    "    DEVICE = \"mps\"\n",
    "print(f\"Using device {DEVICE}\")\n",
    "\n",
    "tokenizer = CLIPTokenizer(\"../data/tokenizer_vocab.json\", merges_file=\"../data/tokenizer_merges.txt\")\n",
    "model_file = \"../data/v1-5-pruned-emaonly.ckpt\"\n",
    "models = model_loader.preload_models_from_standard_weights(model_file, DEVICE)\n",
    "\n",
    "##Text-to-Image\n",
    "\n",
    "prompt = \"A dog eating burger, cinematic, 8k resolution\"\n",
    "uncond_prompt = \"\"\n",
    "do_cfg = True\n",
    "cfg_scale = 7\n",
    "\n",
    "##Image-to-Image\n",
    "\n",
    "input_image = None\n",
    "image_path= \"../images/dog.jpg\"\n",
    "strength = 0.9\n",
    "\n",
    "sampler = \"ddpm\"\n",
    "num_inference_steps = 50\n",
    "seed = 42\n",
    "\n",
    "output_image = pipeline.generase(prompt=prompt, uncond_prompt=uncond_prompt, input_image=input_image, strength= strength, do_cfg=do_cfg, cfg_scale=cfg_scale, sampler_name=sampler, num_inference_steps=num_inference_steps, seed= seed, models=models, device=DEVICE, idle_device=\"cpu\", tokenizer=tokenizer)\n",
    "\n",
    "Image.fromarray(output_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
